{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import logging\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import urllib.request\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from user_agents import parse as parse_ua\n",
    "from jinja2 import Template\n",
    "import geoip2.database\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pycountry\n",
    "\n",
    "# Constants\n",
    "GEO_DB_URL = \"https://github.com/P3TERX/GeoLite.mmdb/releases/latest/download/GeoLite2-Country.mmdb\"\n",
    "LOCAL_GEO_DB = \"GeoLite2-Country.mmdb\"\n",
    "LOG_RE = re.compile(\n",
    "    r'(?P<ip>\\S+) - - \\[(?P<ts>.*?)\\] '\n",
    "    r'\"(?P<method>\\w+) (?P<url>\\S+) HTTP/\\d\\.\\d\" '\n",
    "    r'(?P<status>\\d+) \\d+ \"(?P<ref>.*?)\" \"(?P<ua>.*?)\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bc85ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_TEMPLATE = \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"utf-8\" />\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
    "  <title>B&amp;B Website Dashboard</title>\n",
    "  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap\" rel=\"stylesheet\" />\n",
    "  <style>\n",
    "    body {\n",
    "      font-family: 'Inter', sans-serif;\n",
    "      max-width: 900px;\n",
    "      margin: auto;\n",
    "      padding: 1rem;\n",
    "      background: #f8f9fa;\n",
    "      color: #333;\n",
    "    }\n",
    "    h1, h2 {\n",
    "      font-weight: 700;\n",
    "      color: #2c3e50;\n",
    "      margin-bottom: 0.5rem;\n",
    "    }\n",
    "    .summary {\n",
    "      display: flex;\n",
    "      justify-content: space-around;\n",
    "      flex-wrap: wrap;\n",
    "      gap: 1.5rem;\n",
    "      margin-bottom: 2rem;\n",
    "    }\n",
    "    .summary .card {\n",
    "      flex: 1 1 200px;\n",
    "      background: #fff;\n",
    "      color: #2c3e50;\n",
    "      padding: 1.2rem 1.5rem;\n",
    "      border-radius: 12px;\n",
    "      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "      text-align: center;\n",
    "      min-height: 120px;\n",
    "    }\n",
    "    .summary .card .value {\n",
    "      font-size: 2rem;\n",
    "      font-weight: 900;\n",
    "      margin-top: 0.2rem;\n",
    "    }\n",
    "    img {\n",
    "      max-width: 100%;\n",
    "      border-radius: 8px;\n",
    "      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "      margin-bottom: 1.5rem;\n",
    "    }\n",
    "    table {\n",
    "      width: 100%;\n",
    "      border-radius: 8px;\n",
    "      overflow: hidden;\n",
    "      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "      margin-bottom: 1.5rem;\n",
    "      background: #fff;\n",
    "    }\n",
    "    th, td {\n",
    "      padding: 0.75rem 1rem;\n",
    "      text-align: left;\n",
    "      border-bottom: 1px solid #e9ecef;\n",
    "    }\n",
    "    thead th {\n",
    "      background: #2c3e50;\n",
    "      color: white;\n",
    "      font-weight: 700;\n",
    "      font-size: 1rem;\n",
    "    }\n",
    "    tbody tr:nth-child(even) td {\n",
    "      background: #f8f9fa;\n",
    "    }\n",
    "    tbody tr:hover td {\n",
    "      background: #e9ecef;\n",
    "    }\n",
    "    a {\n",
    "      color: #3498db;\n",
    "      text-decoration: none;\n",
    "    }\n",
    "    a:hover {\n",
    "      text-decoration: underline;\n",
    "    }\n",
    "    p.small {\n",
    "      font-size: 0.85rem;\n",
    "      color: #7f8c8d;\n",
    "      margin-top: 2rem;\n",
    "      text-align: center;\n",
    "    }\n",
    "    @media (max-width: 576px) {\n",
    "      .summary {\n",
    "        flex-direction: column;\n",
    "      }\n",
    "      .summary .card {\n",
    "        flex: unset;\n",
    "      }\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1 class=\"mb-4\">Website Dashboard <small class=\"text-muted\">({{ generated }})</small></h1>\n",
    "\n",
    "  <div class=\"summary\">\n",
    "    <div class=\"card\">\n",
    "      <div>Total Sessions</div>\n",
    "      <div class=\"value\">{{ total_visits }}</div>\n",
    "    </div>\n",
    "    <div class=\"card\">\n",
    "      <div>Unique Visitors</div>\n",
    "      <div class=\"value\">{{ unique_ips }}</div>\n",
    "    </div>\n",
    "    <div class=\"card\">\n",
    "      <div>Avg. Session Duration</div>\n",
    "      <div class=\"value\">{{ \"%.1f\"|format(avg_len) }} min</div>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <h2>Sessions by Day of Week</h2>\n",
    "  <img src=\"{{ base_url }}/sessions_dow.png\" alt=\"Sessions per weekday\" loading=\"lazy\" />\n",
    "\n",
    "  <h2>Top 5 Landing Pages</h2>\n",
    "  <img src=\"{{ base_url }}/top5_pages.png\" alt=\"Top landing pages\" loading=\"lazy\" />\n",
    "\n",
    "  <h2>Avg. Session Duration by Day</h2>\n",
    "  <img src=\"{{ base_url }}/avg_len_dow.png\" alt=\"Avg session length per weekday\" loading=\"lazy\" />\n",
    "\n",
    "  <h2>Sessions by Hour of Day</h2>\n",
    "  <img src=\"{{ base_url }}/sessions_by_hour.png\" alt=\"Sessions by hour\" loading=\"lazy\" />\n",
    "\n",
    "  <h2>Top 5 External Referrers</h2>\n",
    "  <table class=\"table\">\n",
    "    <thead><tr><th>Referrer URL</th><th>Sessions</th></tr></thead>\n",
    "    <tbody>\n",
    "    {% for ref,sessions in top5_ref %}\n",
    "      <tr><td><a href=\"{{ ref }}\" target=\"_blank\" rel=\"noopener\">{{ ref }}</a></td><td>{{ sessions }}</td></tr>\n",
    "    {% endfor %}\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <h2>Top 5 Countries</h2>\n",
    "  <img src=\"{{ base_url }}/top5_countries.png\" alt=\"Top countries\" loading=\"lazy\" />\n",
    "\n",
    "  <p class=\"small\">\n",
    "    * GeoIP via MaxMind GeoLite2 (free).<br />\n",
    "    * Bots filtered out; your domain \"{{ domain }}\" excluded from referrers.<br />\n",
    "    * All metrics are session-based (30-minute timeout).\n",
    "  </p>\n",
    "</body>\n",
    "</html>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "638ca8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_geodb(path: str):\n",
    "    if not os.path.isfile(path):\n",
    "        print(\"Downloading GeoLite2 DB to %s ...\", path)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(GEO_DB_URL, path)\n",
    "            print(\"GeoLite2 DB downloaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to download GeoLite2 DB: %s\", e)\n",
    "            raise\n",
    "\n",
    "\n",
    "def is_bot_or_suspicious(ua: str, ref: str, domain: str, url: str, method: str):\n",
    "    ua = ua.lower()\n",
    "    bot_indicators = [\n",
    "        \"bot\", \"crawler\", \"spider\", \"crawl\", \"slurp\", \"search\",\n",
    "        \"archive\", \"transcoder\", \"monitor\", \"fetch\", \"loader\",\n",
    "        \"python-requests\", \"httpclient\", \"java\", \"wget\", \"curl\",\n",
    "        \"lighthouse\", \"axios\", \"scrapy\", \"httpx\", \"phantomjs\",\n",
    "        \"headless\", \"libwww\", \"mechanize\", \"apachebench\"\n",
    "    ]\n",
    "    if any(indicator in ua for indicator in bot_indicators):\n",
    "        return True\n",
    "\n",
    "    suspicious_patterns = ['/wp-admin/', '/admin/', '/login/', '/phpmyadmin/']\n",
    "    suspicious_methods = ['POST', 'PUT', 'DELETE']\n",
    "    if any(pattern in url for pattern in suspicious_patterns) or method in suspicious_methods:\n",
    "        return True\n",
    "\n",
    "    if ref == '-' or domain in ref:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def parse_log_line(line: str, domain: str):\n",
    "    m = LOG_RE.match(line)\n",
    "    if not m:\n",
    "        return None\n",
    "    d = m.groupdict()\n",
    "    try:\n",
    "        dt = datetime.strptime(d['ts'], '%d/%b/%Y:%H:%M:%S %z')\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        'ip': d['ip'],\n",
    "        'dt': dt,\n",
    "        'url': d['url'],\n",
    "        'status': int(d['status']),\n",
    "        'ref': d['ref'],\n",
    "        'ua': d['ua'],\n",
    "        'method': d['method']\n",
    "    }\n",
    "\n",
    "\n",
    "def load_and_clean(logpath: str, domain: str, start_date: datetime):\n",
    "    rows = []\n",
    "    try:\n",
    "        with open(logpath, errors='ignore') as f:\n",
    "            for line in f:\n",
    "                rec = parse_log_line(line, domain)\n",
    "                if rec and rec['dt'] >= start_date:\n",
    "                    rows.append(rec)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read log file: %s\", e)\n",
    "        raise\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.sort_values('dt', inplace=True)\n",
    "    df['url'] = df['url'].str.replace(r'index\\.html$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def identify_sessions(df: pd.DataFrame):\n",
    "    df['prev'] = df.groupby('ip')['dt'].shift()\n",
    "    df['gap_m'] = (df['dt'] - df['prev']).dt.total_seconds().div(60).fillna(31)\n",
    "    df['new_sess'] = df['gap_m'] > 30\n",
    "    df['sess_id'] = df.groupby('ip')['new_sess'].cumsum().astype(\n",
    "        str).radd(df['ip'] + '_')\n",
    "\n",
    "\n",
    "    sess_summary = df.groupby('sess_id').agg({\n",
    "        'dt': ['min', 'max'],\n",
    "        'ip': 'first',\n",
    "        'url': 'first',\n",
    "        'ref': 'first',\n",
    "        'ua': 'first',\n",
    "        'method': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "\n",
    "    sess_summary.columns = ['sess_id', 'start', 'end',\n",
    "                            'ip', 'landing_page', 'referrer', 'ua', 'method']\n",
    "    sess_summary['duration'] = (\n",
    "        sess_summary['end'] - sess_summary['start']).dt.total_seconds().div(60)\n",
    "\n",
    "    return sess_summary, df\n",
    "\n",
    "\n",
    "def filter_sessions(sess_summary: pd.DataFrame, domain: str):\n",
    "    filtered_sessions = sess_summary[~sess_summary.apply(\n",
    "        lambda row: is_bot_or_suspicious(\n",
    "            row['ua'], row['referrer'], domain, row['landing_page'], row['method']),\n",
    "        axis=1\n",
    "    )]\n",
    "    return filtered_sessions\n",
    "\n",
    "\n",
    "def ensure_dirs(base: str = 'output', period: str = 'w'):\n",
    "    now = datetime.now()\n",
    "    if period == 'w':\n",
    "        fld = f\"w-{now:%Y-%m-%d}\"\n",
    "    elif period == 'm':\n",
    "        fld = f\"m-{now:%Y-%m}\"\n",
    "    elif period == 'y':\n",
    "        fld = f\"y-{now:%Y}\"\n",
    "    else:\n",
    "        fld = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    img_dir = os.path.join(base, fld, 'images')\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    return base, fld, img_dir\n",
    "\n",
    "\n",
    "def save_plotly(fig: go.Figure, out_dir: str, fname: str):\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        margin=dict(t=40, b=20, l=30, r=20),\n",
    "        font=dict(family=\"Inter, sans-serif\", size=14)\n",
    "    )\n",
    "    try:\n",
    "        fig.write_image(os.path.join(out_dir, fname))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to save Plotly figure: %s\", e)\n",
    "        raise\n",
    "\n",
    "\n",
    "def generate_visualizations(sess: pd.DataFrame, df: pd.DataFrame, img_dir: str, domain: str):\n",
    "    total_visits = len(sess)\n",
    "    unique_ips = sess['ip'].nunique()\n",
    "    avg_len = sess['duration'].mean()\n",
    "\n",
    "\n",
    "    dow = sess['start'].dt.day_name().value_counts().reindex(\n",
    "        ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']).fillna(0)\n",
    "    fig = px.bar(\n",
    "        x=dow.index, y=dow.values,\n",
    "        labels={'x': 'Day', 'y': 'Sessions'},\n",
    "        title=\"Sessions per Weekday\",\n",
    "        color=dow.values,\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "    save_plotly(fig, img_dir, \"sessions_dow.png\")\n",
    "\n",
    "\n",
    "    landing_pages = df['url'].copy()\n",
    "    landing_pages = landing_pages[\n",
    "        landing_pages.str.endswith('.html') |\n",
    "        landing_pages.str.endswith('/') |\n",
    "        (landing_pages == '')\n",
    "    ]\n",
    "    landing_pages = landing_pages.str.replace(r'index\\.html$', '', regex=True)\n",
    "    top5_pages = landing_pages.value_counts().iloc[:5]\n",
    "\n",
    "    fig = px.bar(\n",
    "        x=top5_pages.values, y=top5_pages.index,\n",
    "        orientation='h',\n",
    "        labels={'x': 'Sessions', 'y': 'Landing Page'},\n",
    "        title=\"Top 5 Landing Pages\",\n",
    "        color=top5_pages.values,\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "    save_plotly(fig, img_dir, \"top5_pages.png\")\n",
    "\n",
    "\n",
    "    avg_by_dow = sess.groupby(sess['start'].dt.day_name())['duration'].mean().reindex(\n",
    "        ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']).fillna(0)\n",
    "    fig = px.bar(\n",
    "        x=avg_by_dow.index, y=avg_by_dow.values,\n",
    "        labels={'x': 'Day', 'y': 'Avg Duration (min)'},\n",
    "        title=\"Avg Session Length by Weekday\",\n",
    "        color=avg_by_dow.values,\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "    save_plotly(fig, img_dir, \"avg_len_dow.png\")\n",
    "\n",
    "\n",
    "    hrs = sess['start'].dt.hour.value_counts().sort_index()\n",
    "    fig = px.bar(\n",
    "        x=hrs.index, y=hrs.values,\n",
    "        labels={'x': 'Hour of Day', 'y': 'Sessions'},\n",
    "        title=\"Sessions by Hour of Day\",\n",
    "        color=hrs.values,\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "    save_plotly(fig, img_dir, \"sessions_by_hour.png\")\n",
    "\n",
    "\n",
    "    ext_referrers = sess.loc[(sess['referrer'] != '-') &\n",
    "                             (~sess['referrer'].str.contains(domain, na=False)), 'referrer']\n",
    "    ext_ref_counts = ext_referrers.value_counts().iloc[:5]\n",
    "    top5_ref = list(ext_ref_counts.items())\n",
    "\n",
    "\n",
    "    reader = geoip2.database.Reader(LOCAL_GEO_DB)\n",
    "\n",
    "    def lookup_country(ip: str):\n",
    "        try:\n",
    "            return reader.country(ip).country.iso_code or 'Unknown'\n",
    "        except geoip2.errors.AddressNotFoundError:\n",
    "            return 'Unknown'\n",
    "\n",
    "    sess['country'] = sess['ip'].apply(lookup_country)\n",
    "    reader.close()\n",
    "\n",
    "    cc = sess['country'].value_counts()\n",
    "    top5c = cc.iloc[:5]\n",
    "    fig = px.bar(\n",
    "        x=top5c.index, y=top5c.values,\n",
    "        labels={'x': 'Country', 'y': 'Sessions'},\n",
    "        title=\"Top 5 Visitor Countries\",\n",
    "        color=top5c.values,\n",
    "        color_continuous_scale=px.colors.sequential.Blues\n",
    "    )\n",
    "    save_plotly(fig, img_dir, \"top5_countries.png\")\n",
    "\n",
    "    return {\n",
    "        'total_visits': total_visits,\n",
    "        'unique_ips': unique_ips,\n",
    "        'avg_len': avg_len,\n",
    "        'top5_ref': top5_ref\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_html(template_data: Dict[str, Any], base_url: str, domain: str, output_path: str):\n",
    "    try:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            tpl = Template(HTML_TEMPLATE)\n",
    "            f.write(tpl.render(\n",
    "                generated=datetime.now().strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                base_url=base_url,\n",
    "                domain=domain,\n",
    "                **template_data\n",
    "            ))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to generate HTML: %s\", e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edccf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 sessions found\n",
      "Avg session duration: 10 minutes\n",
      "Counter({'/': 62, '/r%C3%A9server.html': 18, '/en/': 8, '/assets/': 6, '/assets/olivier/': 1, '/mentions-l%C3%A9gales.html': 1})\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from collections import Counter\n",
    "\n",
    "log_pattern = re.compile(\n",
    "    r'(?P<ip>\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+-\\s+-\\s+'\n",
    "    r'\\[(?P<timestamp>[^\\]]+)\\]\\s+'\n",
    "    r'\"(?P<method>[A-Z]+)\\s(?P<url>\\S+)\\s(?P<protocol>[^\"]+)\"\\s+'\n",
    "    r'(?P<status>\\d{3})\\s+'\n",
    "    r'(?P<size>\\d+|-)\\s+'\n",
    "    r'\"(?P<referrer>[^\"]*)\"\\s+'\n",
    "    r'\"(?P<user_agent>[^\"]+)\"'\n",
    ")\n",
    "referrer_regex = re.compile(r\"^(-|.*loucantou\\.yvelin\\.net.*)?$\")\n",
    "\n",
    "now = datetime.now(timezone.utc)\n",
    "start_date = now - timedelta(days=7)\n",
    "sessions = {}\n",
    "\n",
    "index = 0\n",
    "\n",
    "with open(\"logs/loucantou-access.log\", errors='ignore') as f:\n",
    "    for raw_line in f:\n",
    "        index += 1\n",
    "        match = log_pattern.match(raw_line)\n",
    "        if not match:\n",
    "            print(\"NO MATCH\", raw_line)\n",
    "            continue\n",
    "\n",
    "        data = match.groupdict()\n",
    "        data['url'] = data['url'].split('?', 1)[0]\n",
    "        data['referrer'] = data['referrer'].split('?', 1)[0]\n",
    "\n",
    "        if '/logs/' in data['url'] or '/logs/' in data['referrer']:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dt = datetime.strptime(data['timestamp'], '%d/%b/%Y:%H:%M:%S %z')\n",
    "            data['timestamp'] = dt\n",
    "        except ValueError:\n",
    "            print(\"BAD TIMESTAMP\", data['timestamp'])\n",
    "            continue\n",
    "\n",
    "        if dt < start_date:\n",
    "            continue\n",
    "\n",
    "        ip = data['ip']\n",
    "        # if index == 23498:\n",
    "        #     print(data)\n",
    "\n",
    "        if ip not in sessions:\n",
    "            sessions[ip] = [[data]]\n",
    "        else:\n",
    "            last_session = sessions[ip][-1]\n",
    "            last_dt = last_session[-1]['timestamp']\n",
    "            if (dt - last_dt).total_seconds() > 1800:\n",
    "                sessions[ip].append([data])\n",
    "            else:\n",
    "                last_session.append(data)\n",
    "\n",
    "user_sessions = []\n",
    "for ip, session_list in sessions.items():\n",
    "    for session in session_list:\n",
    "        if all(\n",
    "            all(\n",
    "                referrer_regex.match(ref)\n",
    "                for ref in (line.get('referrer') for line in session)\n",
    "            )\n",
    "            for session in session_list\n",
    "        ):\n",
    "            continue\n",
    "        user_sessions.append((ip, session))\n",
    "\n",
    "print(len(user_sessions), \"sessions found\")\n",
    "\n",
    "avg_session_duration = statistics.mean(\n",
    "    (session[-1]['timestamp'] - session[0]['timestamp']).total_seconds()\n",
    "    for _, session in user_sessions\n",
    ")\n",
    "print(\"Avg session duration:\", *(\n",
    "    f\"{int(m) + int(s / 60)} minutes\" for m, s in [divmod(avg_session_duration, 60)]\n",
    "))\n",
    "\n",
    "\n",
    "all_pages = [line['url'].replace('index.html', '')\n",
    "                for _, session in user_sessions for line in session if line['url'].endswith('.html') or line['url'].endswith('/')]\n",
    "all_pages = [url.replace('index.html', '') for url in all_pages]\n",
    "print(Counter(all_pages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a07649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main() -> None:\n",
    "    # parser = argparse.ArgumentParser(\n",
    "    #     description=\"Analyze website traffic (session-based)\")\n",
    "    # parser.add_argument('--logpath', required=True, help=\"Path to access.log\")\n",
    "    # parser.add_argument('--domain', required=True,\n",
    "    #                     help=\"Your own domain to exclude\")\n",
    "    # parser.add_argument(\n",
    "    #     '--period', choices=['w', 'm', 'y'], default='w', help=\"w=weekly, m=monthly, y=yearly\")\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    # Calculate start date based on the period\n",
    "    now = datetime.now(timezone.utc)\n",
    "    start_date = now - timedelta(days=7)\n",
    "    # if args.period == 'w':\n",
    "    #     start_date = now - timedelta(days=7)\n",
    "    # elif args.period == 'm':\n",
    "    #     start_date = now - timedelta(days=30)\n",
    "    # elif args.period == 'y':\n",
    "    #     start_date = now - timedelta(days=365)\n",
    "    # else:\n",
    "    #     start_date = now - timedelta(days=7)\n",
    "\n",
    "    download_geodb(LOCAL_GEO_DB)\n",
    "\n",
    "    # base, folder, img_dir = ensure_dirs('output', args.period)\n",
    "    base, folder, img_dir = ensure_dirs('output', \"w\")\n",
    "    raw_base = \"https://raw.githubusercontent.com/L-Yvelin/loucantou/refs/heads/main/output\"\n",
    "    base_url = f\"{raw_base}/{folder}/images\"\n",
    "\n",
    "    # df = load_and_clean(args.logpath, args.domain, start_date)\n",
    "    df = load_and_clean(\"logs/loucantou-access.log\",\n",
    "                        \"loucantou.yvelin.net\", start_date)\n",
    "    sess, df_enriched = identify_sessions(df)\n",
    "    # sess = filter_sessions(sess, args.domain)\n",
    "    sess = filter_sessions(sess, \"loucantou.yvelin.net\")\n",
    "\n",
    "    # template_data = generate_visualizations(\n",
    "    #     sess, df, img_dir, args.domain)\n",
    "    template_data = generate_visualizations(\n",
    "        sess, df, img_dir, \"loucantou.yvelin.net\")\n",
    "\n",
    "    html_out = os.path.join(base, folder, \"dashboard.html\")\n",
    "    # generate_html(template_data, base_url, args.domain, html_out)\n",
    "    generate_html(template_data, base_url, \"loucantou.yvelin.net\", html_out)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2ad02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
